{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8Fa1L/SekpnElXQb8hEN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riz-waan/VIGORMM/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPWjoaj12bm6",
        "outputId": "d90288dd-45be-4c85-b1e4-41f03471c990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, UpSampling1D, Lambda, concatenate\n",
        "from keras.models import Model\n",
        "from random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "training_file = open('drive/MyDrive/VIGOR/AE/CSVs/training.csv', 'r')\n",
        "training_file2 = open('drive/MyDrive/VIGOR/AE/CSVs/training2.csv', 'r')\n",
        "target_file = open('drive/MyDrive/VIGOR/AE/CSVs/target.csv')\n",
        "training_data = []\n",
        "training_data2 = []\n",
        "target_data = []\n",
        "\n",
        "v_training_file = open('drive/MyDrive/VIGOR/AE/NW-CSVs/training-2-1.csv', 'r')\n",
        "v_training_file2 = open('drive/MyDrive/VIGOR/AE/NW-CSVs/training-2-2.csv', 'r')\n",
        "v_target_file = open('drive/MyDrive/VIGOR/AE/NW-CSVs/target-2.csv')\n",
        "v_training_data = []\n",
        "v_training_data2 = []\n",
        "v_target_data = []\n",
        "\n",
        "'''\n",
        "Training data\n",
        "'''\n",
        "for line in training_file.readlines():\n",
        "    for data in line.split(\",\"):\n",
        "        if data != \"\\n\" or data != \"\":\n",
        "            try:\n",
        "                training_data.append(float(data))\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "for line in training_file2.readlines():\n",
        "    for data in line.split(\",\"):\n",
        "        if data != \"\\n\" or data != \"\":\n",
        "            try:\n",
        "                training_data2.append(float(data))\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "for line in target_file.readlines():\n",
        "    for data in line.split(\",\"):\n",
        "        if data != \"\\n\" or data != \"\":\n",
        "            try:\n",
        "                target_data.append(float(data))\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "'''\n",
        "Validation data\n",
        "'''\n",
        "for line in v_training_file.readlines():\n",
        "    for data in line.split(\",\"):\n",
        "        if data != \"\\n\" or data != \"\":\n",
        "            try:\n",
        "                v_training_data.append(float(data))\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "for line in v_training_file2.readlines():\n",
        "    for data in line.split(\",\"):\n",
        "        if data != \"\\n\" or data != \"\":\n",
        "            try:\n",
        "                v_training_data2.append(float(data))\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "for line in v_target_file.readlines():\n",
        "    for data in line.split(\",\"):\n",
        "        if data != \"\\n\" or data != \"\":\n",
        "            try:\n",
        "                v_target_data.append(float(data))\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Setting both as target data just for testing purposes to get past errors\n",
        "x_train = np.reshape(training_data, (-1, 9, 1))  # adapt this if using `channels_first` image data format\n",
        "x_train2 = np.reshape(training_data2, (-1, 9, 1))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(target_data, (-1, 18, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train2 = x_train2.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "v_train = np.reshape(v_training_data, (-1, 9, 1))  # adapt this if using `channels_first` image data format\n",
        "v_train2 = np.reshape(v_training_data2, (-1, 9, 1))  # adapt this if using `channels_first` image data format\n",
        "v_test = np.reshape(v_target_data, (-1, 18, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "v_train = v_train.astype('float32')\n",
        "v_train2 = v_train2.astype('float32')\n",
        "v_test = v_test.astype('float32')\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/questions/43196636/how-to-concatenate-two-layers-in-keras\n",
        "input_img = Input(shape=(9, 1))  # adapt this if using `channels_first` image data format\n",
        "x = Conv1D(32, 3, activation='linear', padding='same')(input_img)\n",
        "x = Dropout(0.5)(x)\n",
        "encoded = MaxPooling1D(3, padding='same')(x)\n",
        "\n",
        "x = Conv1D(32, 3, activation='linear', padding='same')(x)\n",
        "# x = Dropout(0.2)(x)\n",
        "x = UpSampling1D(1)(x)\n",
        "decoded = Conv1D(1, 3, activation='linear', padding='same')(x)\n",
        "\n",
        "input_img2 = Input(shape=(9, 1))  # adapt this if using `channels_first` image data format\n",
        "x2 = Conv1D(32, 3, activation='linear', padding='same')(input_img2)\n",
        "x2 = Dropout(0.5)(x2)\n",
        "encoded2 = MaxPooling1D(3, padding='same')(x2)\n",
        "\n",
        "x2 = Conv1D(32, 3, activation='linear', padding='same')(x2)\n",
        "# x = Dropout(0.2)(x)\n",
        "x2 = UpSampling1D(1)(x2)\n",
        "decoded2 = Conv1D(1, 3, activation='linear', padding='same')(x2)\n",
        "\n",
        "concat = concatenate([decoded, decoded2], axis=1)\n",
        "\n",
        "autoencoder = Model(inputs=[input_img, input_img2], outputs=concat)\n",
        "# plot_model(autoencoder, to_file='autoencoder.png')\n",
        "autoencoder.compile(\"adam\", loss='mse')\n",
        "\n",
        "autoencoder.fit([x_train, x_train2], x_test,\n",
        "                epochs=500,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=([v_train, v_train2], v_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
        "\n",
        "autoencoder.save(\"drive/MyDrive/VIGOR/AE/Models/dae-xyz-v4b.h5\")"
      ],
      "metadata": {
        "id": "KwGF8W3U3krA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}